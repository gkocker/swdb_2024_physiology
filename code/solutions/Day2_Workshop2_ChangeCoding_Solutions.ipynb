{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655252d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Header: introduce dataset and goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11244721",
   "metadata": {},
   "source": [
    "![Image](../../resources/cropped-SummerWorkshop_Header.png)\n",
    "\n",
    "<h1 align=\"center\">Population Coding</h1> \n",
    "<h2 align=\"center\"> Day 2, Afternoon Session</h2> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f95c14",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "In the first workshop of today, we examined how sensory variables can be encoded in individual neurons' activity. We now turn our attention to the coordinated activity of groups of neurons: population codes!\n",
    "    \n",
    "### How do populations of neurons encode information about task-relevant sensory information? \n",
    "### How are these population codes modulated by task context or behavioral state? \n",
    "### What other types of thing are encoded in population activity?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e3a1a6e",
   "metadata": {},
   "source": [
    "<div style=\"background: #E6E6FA; border-radius: 3px; padding: 10px;\">\n",
    "<p>\n",
    "\n",
    "### Data access - loading an experiment of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1bf979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import brain_observatory_utilities.datasets.behavior.data_formatting as behavior_utils\n",
    "\n",
    "from allensdk.brain_observatory.behavior.behavior_project_cache.\\\n",
    "    behavior_neuropixels_project_cache \\\n",
    "    import VisualBehaviorNeuropixelsProjectCache\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e49ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "platstring = platform.platform()\n",
    "\n",
    "if 'Darwin' in platstring:\n",
    "    # macOS \n",
    "    data_root = \"/Volumes/Brain2024/\"\n",
    "elif 'Windows'  in platstring:\n",
    "    # Windows (replace with the drive letter of USB drive)\n",
    "    data_root = \"E:/\"\n",
    "elif ('amzn' in platstring):\n",
    "    # then on CodeOcean\n",
    "    data_root = \"/data/\"\n",
    "else:\n",
    "    # then your own linux platform\n",
    "    # EDIT location where you mounted hard drive\n",
    "    data_root = \"/media/$USERNAME/Brain2024/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = VisualBehaviorNeuropixelsProjectCache.from_local_cache(cache_dir=data_root, use_static_cache=True)\n",
    "\n",
    "# get the metadata tables\n",
    "units_table = cache.get_unit_table()\n",
    "\n",
    "channels_table = cache.get_channel_table()\n",
    "\n",
    "probes_table = cache.get_probe_table()\n",
    "\n",
    "behavior_sessions_table = cache.get_behavior_session_table()\n",
    "\n",
    "ecephys_sessions_table = cache.get_ecephys_session_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65e6aa9",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "### Grab data from a session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcd2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "session = cache.get_ecephys_session(\n",
    "           ecephys_session_id=1065437523)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b28561c",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "    \n",
    "The stimulus presentations table is a record of every stimulus we presented to the mouse over the course of this experiment. Let's take a look at this table. \n",
    "    \n",
    "Here, we'll use an annotated version that includes some extra behavioral information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations = behavior_utils.get_annotated_stimulus_presentations(session)\n",
    "stimulus_presentations.head(-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0335b30",
   "metadata": {},
   "source": [
    "### It contains a great deal of information about the stimulus presentations! Let's look at all the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eae999",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(stimulus_presentations.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6fce4f",
   "metadata": {},
   "source": [
    "The experiment is divided into stimulus blocks. During each block a different set of stimuli are presented. A stimulus block can be active or passive. In active blocks, the mouse performs the change detection task introduced earlier. In passive blocks, there is no task.\n",
    "\n",
    "The different types of stimuli are indexed by the 'stimulus_block' column. Notice that our annotated stimulus table only has block 0, in which natural images are shown. What are the other stimulus blocks?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba9126b",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "What stimuli were shown in stimulus block 0? (Remember: our \"stimulus_presentations\" table already contains only this block.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e670b8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations['image_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc20e0",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">    \n",
    "\n",
    "What are all the types of stimulus block that were presented in this session?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6588d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stimulus_presentations = session.stimulus_presentations\n",
    "all_stimulus_presentations.groupby('stimulus_block')[['stimulus_block', \n",
    "                                                'stimulus_name', \n",
    "                                                'active', \n",
    "                                                'duration', \n",
    "                                                'start_time']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cc899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stimulus_presentations['stimulus_name'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32b1ea",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "What stimuli were shown in stimulus block 0? (Remember: our \"stimulus_presentations\" table already contains only this block.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd9214",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus_presentations.head(-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474b4067",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(stimulus_presentations['image_name'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2520e1",
   "metadata": {},
   "source": [
    "### Moving forwards, we will only look at this stimulus block, 0, where the mouse is performing the change detection task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ef4290",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "How many stimulus presentations are there and how many image changes (in block 0)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d771d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_presentations = len(stimulus_presentations)\n",
    "num_changes = np.sum(stimulus_presentations['is_change'].values)\n",
    "\n",
    "print('{} stimulus presentations'.format(num_presentations))\n",
    "print('{} image changes'.format(num_changes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a1aec7d",
   "metadata": {},
   "source": [
    "### The (annotated) stimulus presentation table also includes information about the mouse behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b5175c",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "How well does the mouse do the task? What are its hit and miss rates? \n",
    "    \n",
    "(Note that the first few trials are auto-rewarded, and should not be counted.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e9c151",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_stimulus_presentations = stimulus_presentations[stimulus_presentations['is_change']]\n",
    "num_change_trials = num_changes - np.sum(change_stimulus_presentations['auto_rewarded'])\n",
    "\n",
    "print('Hit rate: {}'.format(np.sum(change_stimulus_presentations['hit']) / num_change_trials ))\n",
    "print('Miss rate: {}'.format(np.sum(change_stimulus_presentations['miss']) / num_change_trials ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7200e0",
   "metadata": {},
   "source": [
    "<div style=\"background: #E6E6FA; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "### Now let's get unit and channel data, sort the units by depth and filter for \"good\" units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac7a1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get unit and channel data, sort the units by depth and filter for \"good\" units\n",
    "units = session.get_units() # contains information about spike waveforms, isolation quality\n",
    "channels = session.get_channels() # contains information about anatomical location\n",
    "\n",
    "unit_channels = units.merge(channels, left_on='peak_channel_id', right_index=True)\n",
    "\n",
    "#first let's sort our units by depth and filter\n",
    "unit_channels = unit_channels.sort_values('probe_vertical_position', ascending=False)\n",
    "\n",
    "#now we'll filter them\n",
    "good_unit_filter = ((unit_channels['snr']>1)&\n",
    "                    (unit_channels['isi_violations']<1)&\n",
    "                    (unit_channels['firing_rate']>0.1))\n",
    "\n",
    "good_units = unit_channels.loc[good_unit_filter]\n",
    "spike_times = session.spike_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd98a46",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    Which brain structures were recorded from in this session? How many units are present in each structure? (Hint: try the \"value_counts\" function.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57950288",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_channels.value_counts('structure_acronym')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b3fec",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "### Let's look at the population activity in primary visual cortex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddd114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_interest = 'VISp'\n",
    "area_units = good_units[good_units['structure_acronym'] == area_of_interest]\n",
    "num_units = len(area_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c1add6",
   "metadata": {},
   "source": [
    "### Let's start by looking at the neural activity! Does it reflect the image presentation?\n",
    "\n",
    "### The session.spike_times object contains all spike times, in seconds, indexed by the unit ID. Let's take a look at this object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee6c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_times = session.spike_times\n",
    "print(type(spike_times))\n",
    "spike_times"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad75dfcb",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "\n",
    "Get the array of spike times for unit 1068230173. How many times does this unit spike in the first minute of the experiment?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfc33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_spike_times = spike_times[1068230173]\n",
    "unit_spike_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0f349",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(unit_spike_times < 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90421fed",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "\n",
    "Plot a population spike raster spanning 1 second before to 1 second after a stimulus presentation. Fill in the code in the for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f269caa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot a single-trial raster, population PSTH, and representation matrix\n",
    "pre_time = 1\n",
    "post_time = 1\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "presentation_idx = 1\n",
    "start_time = stimulus_presentations['start_time'][presentation_idx] # in seconds - start one second before this\n",
    "end_time = stimulus_presentations['end_time'][presentation_idx] # in seconds - go to one second after this\n",
    "\n",
    "unit_num = 0\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]\n",
    "    \n",
    "    unit_spike_times = unit_spike_times[(unit_spike_times >= start_time - pre_time) * (unit_spike_times < end_time + post_time)]\n",
    "    unit_num_spikes = len(unit_spike_times)\n",
    "    \n",
    "    ax.plot(unit_spike_times - start_time, unit_num*np.ones(unit_num_spikes,), 'k|', markersize=5)\n",
    "    unit_num += 1\n",
    "\n",
    "ax.set_title('Single-trial raster')\n",
    "ax.set_xlabel('Time relative to stimulus presentation (s)')\n",
    "ax.set_ylabel('Unit')\n",
    "ax.set_ylim((0, num_units+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64a4acf",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "Now let's compare to a change trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62007f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "### plot a single-trial raster, population PSTH, and representation matrix\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "change_idx = np.where(stimulus_presentations['is_change'].values)[0]\n",
    "presentation_idx = change_idx[0]\n",
    "\n",
    "start_time = stimulus_presentations['start_time'][presentation_idx]\n",
    "end_time = stimulus_presentations['end_time'][presentation_idx]\n",
    "\n",
    "unit_num = 0\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]\n",
    "    \n",
    "    unit_spike_times = unit_spike_times[(unit_spike_times >= start_time - pre_time) * (unit_spike_times < end_time + post_time)]\n",
    "    unit_num_spikes = len(unit_spike_times)\n",
    "    \n",
    "    ax.plot(unit_spike_times - start_time, unit_num*np.ones(unit_num_spikes,), 'k|', markersize=5)\n",
    "    unit_num += 1\n",
    "\n",
    "ax.set_xlabel('Time relative to stimulus presentation (s)')\n",
    "ax.set_ylabel('Unit')\n",
    "ax.set_ylim((0, num_units))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465c256",
   "metadata": {},
   "source": [
    "### Now let's take a look at the trial-averaged responses to see how a neuron encodes the stimulus in its time-dependent firing rate (its peri-stimulus time histogram, or PSTH)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb2ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convenience function to compute the PSTH\n",
    "def makePSTH(spikes, startTimes, windowDur, binSize=0.001):\n",
    "    bins = np.arange(0,windowDur+binSize,binSize)\n",
    "    counts = np.zeros(bins.size-1)\n",
    "    for i,start in enumerate(startTimes):\n",
    "        startInd = np.searchsorted(spikes, start)\n",
    "        endInd = np.searchsorted(spikes, start+windowDur)\n",
    "        counts = counts + np.histogram(spikes[startInd:endInd]-start, bins)[0]\n",
    "    \n",
    "    counts = counts/startTimes.size\n",
    "    return counts/binSize, bins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4818c39",
   "metadata": {},
   "source": [
    "Let's start by plotting the response of unit 0 to one of the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2a7fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli = stimulus_presentations['image_name'].unique()\n",
    "stimulus = stimuli[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d103d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83df7717",
   "metadata": {},
   "outputs": [],
   "source": [
    "presentations = stimulus_presentations[stimulus_presentations['image_name'] == stimulus]\n",
    "num_presentations = len(presentations)\n",
    "\n",
    "start_times = presentations['start_time'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bb2e581",
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_ids = area_units.index\n",
    "iu = unit_ids[0]\n",
    "unit_spike_times = spike_times[iu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6639f1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_before_im = 1\n",
    "duration = 2\n",
    "\n",
    "unit_response, bins = makePSTH(unit_spike_times, \n",
    "                                  start_times - time_before_im, \n",
    "                                  duration, binSize=0.01)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.plot(bins[:-1] - time_before_im, unit_response)\n",
    "ax.set_xlabel('Time from flash (s)')\n",
    "ax.set_ylabel('Firing rate (Hz)')\n",
    "ax.set_title('PSTH for {}'.format(stimulus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fa75e5",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "Plot the PSTHs for every unit to that image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a311e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Plot a set of PSTHs\n",
    "\n",
    "psths = []\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]  \n",
    "    unit_response, bins = makePSTH(unit_spike_times, \n",
    "                                      start_times - time_before_im, \n",
    "                                      duration, binSize=0.01)\n",
    "    \n",
    "    psths.append(unit_response)\n",
    "    ax.plot(bins[:-1]-time_before_im, unit_response)\n",
    "    \n",
    "ax.set_xlabel('Time from flash (s)')\n",
    "ax.set_ylabel('Firing rate (Hz)')\n",
    "ax.set_title('PSTH for {}'.format(stimulus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fc0d5e",
   "metadata": {},
   "source": [
    "### We can see the trial structure of the task reflected in the PSTH. Some units have very strong transient responses to the image presentation. Do these responses depend on the task structure (whether the image is a change or not)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2c716e",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "Plot the PSTHs for every unit to that image on change trials only. Are the same neurons the most responsive on change trials as on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3657630",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_start_times = start_times[presentations['is_change'].values.astype('bool')]\n",
    "\n",
    "psths = []\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]  \n",
    "    unit_response, bins = makePSTH(unit_spike_times, \n",
    "                                      change_start_times - time_before_im, \n",
    "                                      duration, binSize=0.01)\n",
    "    \n",
    "    psths.append(unit_response)\n",
    "    ax.plot(bins[:-1]-time_before_im, unit_response)\n",
    "    \n",
    "ax.set_xlabel('Time from flash (s)')\n",
    "ax.set_ylabel('Firing rate (Hz)')\n",
    "ax.set_title('Change trial PSTH for {}'.format(stimulus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae8389f",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "Plot the PSTHs for every unit to another image on change trials. Do the same neurons have the strongest responses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46d1d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = stimuli[3]\n",
    "\n",
    "presentations = stimulus_presentations[stimulus_presentations['image_name'] == stimulus]\n",
    "start_times = presentations['start_time'].values\n",
    "change_start_times = start_times[presentations['is_change'].values.astype('bool')]\n",
    "\n",
    "num_presentations = len(presentations)\n",
    "\n",
    "start_times = presentations['start_time'].values\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "\n",
    "for iu, unit in area_units.iterrows():\n",
    "    unit_spike_times = spike_times[iu]  \n",
    "    unit_response, bins = makePSTH(unit_spike_times, \n",
    "                                      start_times - time_before_im, \n",
    "                                      duration, binSize=0.01)\n",
    "    \n",
    "    psths.append(unit_response)\n",
    "    ax.plot(bins[:-1]-time_before_im, unit_response)\n",
    "    \n",
    "ax.set_xlabel('Time from flash (s)')\n",
    "ax.set_ylabel('Firing rate (Hz)')\n",
    "ax.set_title('PSTH for {}'.format(stimulus))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091dd7ef",
   "metadata": {},
   "source": [
    "<div style=\"background: #E6E6FA; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "## Training a classifier on population spiking data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6579c18b",
   "metadata": {},
   "source": [
    "Now we'll look at how the population activity encodes the image change. To determine how well we can decode the image change from population activity, we will train a **classifier** on a matrix of firing rates. Whereas regression models try to predict continuous values from the input features, classification models try to predict *labels* (also known as classes) from the input features.\n",
    "\n",
    "### Support Vector Machines\n",
    "\n",
    "Let's start with a linear Support Vector Machine (SVM) classifier, which will try to draw linear boundaries between orientation conditions (the labels) in our high-dimensional firing rate space.\n",
    "\n",
    "This cartoon shows how we would expect an SVM to behave on a dataset with two dimensions and three conditions:\n",
    "\n",
    "![SVM illustration](../../resources/svm-classifier.png)\n",
    "\n",
    "SVM computes decision boundaries in feature space that can be used to classify different conditions. If a new data point appears, the SVM classifier will label it based on where it falls with respect to these boundaries.\n",
    "\n",
    "To train an SVM, we need to import the following methods from `scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f21c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.model_selection import KFold, LeaveOneOut\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a2c41c",
   "metadata": {},
   "source": [
    "### First, we need to create a response matrix and vector of stimulus labels from the presentations that we'll decode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8ecb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Total trials: {}'.format(len(stimulus_presentations)))\n",
    "print('Change trials: {}'.format(np.sum(stimulus_presentations['is_change'].values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333bacfd",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div style=\"border-left: 3px solid #000; padding: 1px; padding-left: 10px; background: #F0FAFF; \">\n",
    "\n",
    "The vast majority of stimulus presentations (~95%) are not a change. So a decoder could get 95% accuracy by predicting that there are no changes!\n",
    "\n",
    "To avoid this, we will balance the trials and decode change vs pre-change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412473a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pre-change\n",
    "stimulus_presentations['pre_change'] = stimulus_presentations['is_change'].shift(-1)\n",
    "\n",
    "# isolate the trials to use for decoding\n",
    "decode_trial_ind = (stimulus_presentations['is_change'].values + stimulus_presentations['pre_change'].values)\n",
    "stimulus_presentations = stimulus_presentations[decode_trial_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f44e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check that the classes are balanced\n",
    "print(len(stimulus_presentations))\n",
    "print(np.sum(stimulus_presentations['is_change']))\n",
    "print(np.sum(stimulus_presentations['pre_change']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3b642a",
   "metadata": {},
   "source": [
    "### Now let's make our matrix of responses and vector of labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6885e92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_response_array(spike_times, stimulus_presentations, units, window=.05):\n",
    "\n",
    "    '''\n",
    "    Create an array of spike counts x stimulus presentations, and a corresponding list of stimulus label\n",
    "    spike_times: spike times \n",
    "    stimulus_presentation: stimulus presentation table\n",
    "    units: units table containing only the units to get the responses of\n",
    "    '''\n",
    "\n",
    "    # sort spike times chronologically; necessary for the binary search later\n",
    "    sorted_spikes = dict()\n",
    "    for iu in units.index:\n",
    "        # mergesort/timsort since most spike_times are already sorted\n",
    "        sorted_spikes[iu] = np.sort(spike_times[iu], kind='mergesort')\n",
    "\n",
    "    # create our own copy of stimulus presentations and sort by presentation start time chronologically\n",
    "    # sortation of stimulus_presentations isn't necessary, but it speeds up the vectorized `searchsorted(...)`\n",
    "    stimulus_presentations = stimulus_presentations.sort_values(by='start_time', kind='mergesort', inplace=False)\n",
    "\n",
    "    # Calculate the duration of stimulus presentations, and drop NaN durations\n",
    "    stimulus_presentations['duration'] = stimulus_presentations['end_time'] - stimulus_presentations['start_time']\n",
    "    stimulus_presentations.dropna(subset='duration', inplace=True)\n",
    "    \n",
    "    # Warn if window size is too big\n",
    "    if np.any(window > stimulus_presentations['duration']):\n",
    "        print('Warning: window size longer than stimulus presentation')\n",
    "\n",
    "    responses_by_unit = list()\n",
    "    for iu in units.index:\n",
    "        unit_spike_times = sorted_spikes[iu]\n",
    "\n",
    "        # Determine the first and last spike time for each stimulus presentation\n",
    "        start_is = np.searchsorted(unit_spike_times, stimulus_presentations['start_time'])\n",
    "        end_is = np.searchsorted(unit_spike_times, stimulus_presentations['start_time']+window)\n",
    "\n",
    "        # presentation_spike_times = unit_spike_times[start_i:end_i]\n",
    "\n",
    "        # Calculate the response rate for each stimulus presentation\n",
    "        responses_by_unit.append((end_is - start_is) / stimulus_presentations['duration'])\n",
    "\n",
    "    # responses_by_unit has each row a unit, and each column a stimulus, flip so that rows are stimuli\n",
    "    responses = np.transpose(responses_by_unit)\n",
    "\n",
    "    # Extract the labels that match the responses from our sorted stimulus presentations table\n",
    "    labels = np.array(stimulus_presentations['is_change']).astype('int')\n",
    "        \n",
    "    # Extract the mouse's behavioral response\n",
    "    hit = np.array(stimulus_presentations['hit']).astype('int')\n",
    "    miss = np.array(stimulus_presentations['miss']).astype('int')\n",
    "   \n",
    "    return responses, labels, hit, miss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4284c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses, labels, hit, miss = make_response_array(spike_times, stimulus_presentations, area_units, window=.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a10fb5",
   "metadata": {},
   "source": [
    "### We will first select a random subset of trials for training the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778764ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_presentations = responses.shape[0]\n",
    "num_train = int(total_presentations * 0.5) # Use 50% of trials for training\n",
    "random_trial_order = np.random.permutation(responses.shape[0])\n",
    "train_indices = random_trial_order[:num_train]\n",
    "\n",
    "training_data = responses[train_indices]\n",
    "training_labels = labels[train_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc65166",
   "metadata": {},
   "source": [
    "### Next, we'll create the model and fit it to our training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2735d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(responses[train_indices], labels[train_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a7ef93",
   "metadata": {},
   "source": [
    "### Now that our model has been trained, we can ask it to classify unlabeled data (i.e., the sets of population firing rates that were not included in our original training set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b96247",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indices = random_trial_order[num_train:]\n",
    "test_data = responses[test_indices]\n",
    "predicted_labels = clf.predict(responses[test_indices])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c260ff5d",
   "metadata": {},
   "source": [
    "### We can compare the predicted labels to the actual labels in order to assess the classifier's performance. We'll assess accuracy as the fraction of correctly predicted test images. As a baseline, we'll also compute the accuracy of a uniform random prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbe2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "conditions = np.unique(labels)\n",
    "\n",
    "actual_labels = labels[test_indices]\n",
    "accuracy = np.mean(actual_labels == predicted_labels)\n",
    "\n",
    "print('Accurary: {}'.format(accuracy))\n",
    "print('Chance level: {}'.format(1/len(conditions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dbbe31",
   "metadata": {},
   "source": [
    "### We see that we perform better than chance! We can get a better sense of classification performance by using leave-one-out cross-validation. The `scikit-learn.model_selection.LeaveOneOut` iterator will automatically cycle through trials, on each iteration using one trial as a test and the others to train the classifier. Note that the model is fit independently on each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b75b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "confusions = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)    \n",
    "#     print(accuracy)\n",
    "    \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize='pred'))\n",
    "    \n",
    "print(f\"\\nmean accuracy: {np.mean(accuracies)}\")\n",
    "print(f\"chance: {1/conditions.size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c31354",
   "metadata": {},
   "source": [
    "The leave-one-out cross-validation roughly agrees with our previous result. Do we do better on change or pre-change images? To assess this we'll look at the confusion matrix, which tells us how frequently each condition is predicted on change and pre-change presentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d567571e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(confusions, conditions, title=None):\n",
    "    \n",
    "    mean_confusion = np.mean(confusions, axis=0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    im = ax.imshow(mean_confusion, cmap='gray_r', clim=(0, 1))\n",
    "    plt.colorbar(im, ax=ax, label='Fraction of classifications')\n",
    "    \n",
    "    ax.set_xticks(range(len(conditions)), conditions, rotation=0)\n",
    "    ax.set_yticks(range(len(conditions)), conditions)\n",
    "\n",
    "    ax.set_xlabel(\"Predicted label\")\n",
    "    ax.set_ylabel(\"Actual label\")\n",
    "    if title is None:\n",
    "        ax.set_title('Confusion Matrix')\n",
    "    elif type(title) is str:\n",
    "        ax.set_title(title)\n",
    "    \n",
    "plot_confusion_matrix(confusions, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b3a481",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "How does this V1-based decoder perform on hit trials vs miss trials?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e325d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "accuracies_hit = []\n",
    "accuracies_miss = []\n",
    "\n",
    "confusions = []\n",
    "confusions_hit = []\n",
    "confusions_miss = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)        \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize=None))\n",
    "    \n",
    "    test_hit = hit[test_indices].astype('bool')\n",
    "    test_miss = miss[test_indices].astype('bool')\n",
    "    \n",
    "    if hit[test_indices].astype('bool'):\n",
    "        accuracies_hit.append(accuracy)\n",
    "        confusions_hit.append(confusion_matrix(y_true=test_targets[test_hit], y_pred=test_predictions[test_hit], labels=conditions, normalize=None))\n",
    "        \n",
    "    elif miss[test_indices].astype('bool'):\n",
    "        accuracies_miss.append(accuracy)\n",
    "        confusions_miss.append(confusion_matrix(y_true=test_targets[test_miss], y_pred=test_predictions[test_miss], labels=conditions, normalize=None))\n",
    "\n",
    "print('Mean accuracy: {}'.format(np.mean(accuracies)))\n",
    "print('Mean accuracy, hit trials: {}'.format(np.mean(accuracies_hit)) )\n",
    "print('Mean accuracy, miss trials: {}'.format(np.mean(accuracies_miss)) ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46753d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusions, conditions=conditions)\n",
    "plot_confusion_matrix(confusions_hit, conditions=conditions, title='Confusion Matrix, Hit Trials')\n",
    "plot_confusion_matrix(confusions_miss, conditions=conditions, title='Confusion Matrix, Miss Trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5a1712",
   "metadata": {},
   "source": [
    "<div style=\"background: #E6E6FA; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "## Exploring the time course of change-related information \n",
    "    \n",
    "Next we'll examine the time course of information in our population! Or more specifically: how the length of the spike count window affects the decoding accuracy. Can we decode the stimulus perfectly if we integrate spikes for long enough?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baaa8734",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "First, let's try decoding with a longer response window of .2 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03c3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "responses, labels, hit, miss = make_response_array(spike_times, stimulus_presentations, area_units, window=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0786e1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies = []\n",
    "confusions = []\n",
    "confusions_hit = []\n",
    "confusions_miss = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)        \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize=None))\n",
    "    \n",
    "    test_hit = hit[test_indices].astype('bool')\n",
    "    test_miss = miss[test_indices].astype('bool')\n",
    "    \n",
    "    if hit[test_indices].astype('bool'):\n",
    "        accuracies_hit.append(accuracy)\n",
    "        confusions_hit.append(confusion_matrix(y_true=test_targets[test_hit], y_pred=test_predictions[test_hit], labels=conditions, normalize=None))\n",
    "        \n",
    "    elif miss[test_indices].astype('bool'):\n",
    "        accuracies_miss.append(accuracy)\n",
    "        confusions_miss.append(confusion_matrix(y_true=test_targets[test_miss], y_pred=test_predictions[test_miss], labels=conditions, normalize=None))\n",
    "\n",
    "print('Mean accuracy: {}'.format(np.mean(accuracies)))\n",
    "print('Mean accuracy, hit trials: {}'.format(np.mean(accuracies_hit)) )\n",
    "print('Mean accuracy, miss trials: {}'.format(np.mean(accuracies_miss)) ) \n",
    "\n",
    "plot_confusion_matrix(confusions, conditions=conditions)\n",
    "plot_confusion_matrix(confusions_hit, conditions=conditions, title='Confusion Matrix, Hit Trials')\n",
    "plot_confusion_matrix(confusions_miss, conditions=conditions, title='Confusion Matrix, Miss Trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9fe5d8d",
   "metadata": {},
   "source": [
    "With a long response window we can discriminate change vs pre-change almost perfectly based on V1 activity!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18775f3",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "How long do we need to integrate spikes in order to saturate the decoding performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_lengths = np.arange(.01, .2, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6705e",
   "metadata": {},
   "source": [
    "Here we'll use a relaxed, K-Fold cross-validation instead of LeaveOneOut for speed purposes. This divides the data set into K pieces, and iterates through them. On each of those K iterations, one piece is used as the \"test\" set and the others are used to train the decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b702b339",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 10\n",
    "accuracies = np.zeros((len(window_lengths), num_splits))\n",
    "accuracies_hit = np.zeros((len(window_lengths), num_splits))\n",
    "accuracies_miss = np.zeros((len(window_lengths), num_splits))\n",
    "\n",
    "for i, window in enumerate(window_lengths):\n",
    "    print('{}/{}'.format(i, len(window_lengths)))\n",
    "    responses, labels, hit, miss = make_response_array(spike_times, stimulus_presentations, area_units, window)\n",
    "    \n",
    "    k = 0\n",
    "    for train_indices, test_indices in KFold(n_splits=num_splits, shuffle=True).split(responses):\n",
    "        clf = svm.SVC()\n",
    "        clf.fit(responses[train_indices], labels[train_indices])\n",
    "\n",
    "        test_targets = labels[test_indices]\n",
    "        test_predictions = clf.predict(responses[test_indices])\n",
    "\n",
    "        accuracies[i, k] = np.mean(test_targets == test_predictions)        \n",
    "        \n",
    "        test_hit = hit[test_indices].astype('bool')\n",
    "        test_miss = miss[test_indices].astype('bool')\n",
    "        \n",
    "        accuracies_hit[i, k] = np.mean(test_targets[test_hit] == test_predictions[test_hit])\n",
    "        accuracies_miss[i, k] = np.mean(test_targets[test_miss] == test_predictions[test_miss])\n",
    "        \n",
    "        k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(x=window_lengths, y=accuracies.mean(axis=(1)), yerr=accuracies.std(axis=(1))/np.sqrt(num_splits), fmt='o-', label='all trials')\n",
    "plt.errorbar(x=window_lengths, y=accuracies_hit.mean(axis=(1)), yerr=accuracies_hit.std(axis=(1))/np.sqrt(num_splits), fmt='o-', label='hit trials')\n",
    "plt.errorbar(x=window_lengths, y=accuracies_miss.mean(axis=(1)), yerr=accuracies_miss.std(axis=(1))/np.sqrt(num_splits), fmt='o-', label='miss trials')\n",
    "\n",
    "plt.xlabel('Spike counting window length (s)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc=0, frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de494657",
   "metadata": {},
   "source": [
    "<div style=\"background: #E6E6FA; border-radius: 3px; padding: 10px;\">\n",
    "    \n",
    "## Relationship between population size and decoding accuracy\n",
    "\n",
    "Next we'll examine how the size of the simultaneously recorded population affects decoding accuracy. In any physiology experiment, we only have a very small window into the overall population response. For example, there are about 500,000 neurons in mouse V1, so in this case we are measuring around 0.02% of the firing rates in this region.\n",
    "\n",
    "As the number of simultaneously recorded neurons increases, we expect that our ability to decode stimulus identity will improve. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a82b8f8",
   "metadata": {},
   "source": [
    "To start with, let's try decoding with a random sample of 10 neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3502d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_size = 10\n",
    "\n",
    "pop_idx = np.random.choice(range(num_units), size=pop_size)\n",
    "responses_pop = responses[:, pop_idx]\n",
    "\n",
    "accuracies = []\n",
    "accuracies_hit = []\n",
    "accuracies_miss = []\n",
    "\n",
    "confusions = []\n",
    "confusions_hit = []\n",
    "confusions_miss = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses_pop[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses_pop[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)        \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize=None))\n",
    "    \n",
    "    test_hit = hit[test_indices].astype('bool')\n",
    "    test_miss = miss[test_indices].astype('bool')\n",
    "    \n",
    "    if hit[test_indices].astype('bool'):\n",
    "        accuracies_hit.append(accuracy)\n",
    "        confusions_hit.append(confusion_matrix(y_true=test_targets[test_hit], y_pred=test_predictions[test_hit], labels=conditions, normalize=None))\n",
    "        \n",
    "    elif miss[test_indices].astype('bool'):\n",
    "        accuracies_miss.append(accuracy)\n",
    "        confusions_miss.append(confusion_matrix(y_true=test_targets[test_miss], y_pred=test_predictions[test_miss], labels=conditions, normalize=None))\n",
    "\n",
    "print('Mean accuracy: {}'.format(np.mean(accuracies)))\n",
    "print('Mean accuracy, hit trials: {}'.format(np.mean(accuracies_hit)) )\n",
    "print('Mean accuracy, miss trials: {}'.format(np.mean(accuracies_miss)) ) \n",
    "\n",
    "        \n",
    "plot_confusion_matrix(confusions, conditions=conditions)\n",
    "plot_confusion_matrix(confusions_hit, conditions=conditions, title='Confusion Matrix, Hit Trials')\n",
    "plot_confusion_matrix(confusions_miss, conditions=conditions, title='Confusion Matrix, Miss Trials')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429f5706",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[hit]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b48d81",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "Does the result depend on which 10 neurons we sampled? Let's try another random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58550b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_idx = np.random.choice(range(num_units), size=pop_size)\n",
    "responses_pop = responses[:, pop_idx]\n",
    "\n",
    "accuracies = []\n",
    "accuracies_hit = []\n",
    "accuracies_miss = []\n",
    "\n",
    "confusions = []\n",
    "confusions_hit = []\n",
    "confusions_miss = []\n",
    "\n",
    "conditions = np.unique(labels)\n",
    "\n",
    "for train_indices, test_indices in LeaveOneOut().split(responses):\n",
    "    \n",
    "    clf = svm.SVC()\n",
    "    clf.fit(responses_pop[train_indices], labels[train_indices])\n",
    "    \n",
    "    test_targets = labels[test_indices]\n",
    "    test_predictions = clf.predict(responses_pop[test_indices])\n",
    "    \n",
    "    accuracy = np.mean(test_targets == test_predictions)        \n",
    "    accuracies.append(accuracy)\n",
    "    confusions.append(confusion_matrix(y_true=test_targets, y_pred=test_predictions, labels=conditions, normalize=None))\n",
    "    \n",
    "    test_hit = hit[test_indices].astype('bool')\n",
    "    test_miss = miss[test_indices].astype('bool')\n",
    "    \n",
    "    if hit[test_indices].astype('bool'):\n",
    "        accuracies_hit.append(accuracy)\n",
    "        confusions_hit.append(confusion_matrix(y_true=test_targets[test_hit], y_pred=test_predictions[test_hit], labels=conditions, normalize=None))\n",
    "        \n",
    "    elif miss[test_indices].astype('bool'):\n",
    "        accuracies_miss.append(accuracy)\n",
    "        confusions_miss.append(confusion_matrix(y_true=test_targets[test_miss], y_pred=test_predictions[test_miss], labels=conditions, normalize=None))\n",
    "\n",
    "print('Mean accuracy: {}'.format(np.mean(accuracies)))\n",
    "print('Mean accuracy, hit trials: {}'.format(np.mean(accuracies_hit)) )\n",
    "print('Mean accuracy, miss trials: {}'.format(np.mean(accuracies_miss)) ) \n",
    "\n",
    "        \n",
    "plot_confusion_matrix(confusions, conditions=conditions)\n",
    "plot_confusion_matrix(confusions_hit, conditions=conditions, title='Confusion Matrix, Hit Trials')\n",
    "plot_confusion_matrix(confusions_miss, conditions=conditions, title='Confusion Matrix, Miss Trials')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1967ae",
   "metadata": {},
   "source": [
    "<div style=\"border-left: 3px solid #000; padding: 10px; padding-left: 10px; padding-bottom: 10px; background: #c8e0bf; \">\n",
    "    \n",
    "### Now, let's try to get a sense for how this changes with the number of neurons we use to train the classifier. \n",
    "    \n",
    "### How many neurons do you need to decode with roughly 50% accuracy? 80%? 90%? Finish the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685a9967",
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_sizes = np.arange(1, num_units+5, 5).astype('int')\n",
    "num_resamples = 10\n",
    "\n",
    "accuracies = np.zeros((len(pop_sizes), num_resamples, num_splits))\n",
    "accuracies_hit = np.zeros((len(pop_sizes), num_resamples, num_splits))\n",
    "accuracies_miss = np.zeros((len(pop_sizes), num_resamples, num_splits))\n",
    "\n",
    "for i, pop_size in enumerate(pop_sizes):\n",
    "    print('population size: {}'.format(pop_size))\n",
    "\n",
    "    for j in range(num_resamples):\n",
    "        pop_idx = np.random.choice(range(num_units), size=pop_size)\n",
    "        responses_pop = responses[:, pop_idx]\n",
    "            \n",
    "        k = 0\n",
    "        for train_indices, test_indices in KFold(n_splits=num_splits, shuffle=True).split(responses):\n",
    "            clf = svm.SVC()\n",
    "            clf.fit(responses_pop[train_indices], labels[train_indices])\n",
    "\n",
    "            test_targets = labels[test_indices]\n",
    "            test_predictions = clf.predict(responses_pop[test_indices])\n",
    "\n",
    "            accuracies[i, j, k] = np.mean(test_targets == test_predictions)        \n",
    "\n",
    "            test_hit = hit[test_indices].astype('bool')\n",
    "            test_miss = miss[test_indices].astype('bool')\n",
    "\n",
    "            accuracies_hit[i, j, k] = np.mean(test_targets[test_hit] == test_predictions[test_hit])\n",
    "            accuracies_miss[i, j, k] = np.mean(test_targets[test_miss] == test_predictions[test_miss])\n",
    "\n",
    "            k += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788b5439",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.errorbar(x=pop_sizes, y=accuracies.mean(axis=(1, 2)), yerr=accuracies.std(axis=(1, 2))/np.sqrt(num_splits), fmt='o-')\n",
    "plt.errorbar(x=pop_sizes, y=accuracies_hit.mean(axis=(1, 2)), yerr=accuracies_hit.std(axis=(1, 2))/np.sqrt(num_splits), fmt='o-')\n",
    "plt.errorbar(x=pop_sizes, y=accuracies_miss.mean(axis=(1, 2)), yerr=accuracies_miss.std(axis=(1, 2))/np.sqrt(num_splits), fmt='o-')\n",
    "\n",
    "plt.xlabel('Population size')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82af6368",
   "metadata": {},
   "source": [
    "Roughly how many neurons do you need to decode with 50% accuracy? 80%? 90%?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de54b31",
   "metadata": {},
   "source": [
    "# With these analyses in hand, we leave you with some questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63c00a",
   "metadata": {},
   "source": [
    "### If you integrate spikes in a fixed window length, how does the decoding accuracy depend on the time since the image presentation? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c7a1a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7626587d",
   "metadata": {},
   "source": [
    "### Where do the lick time distributions fall on the decoding accuracy vs time curve?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1480cbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "167e64c4",
   "metadata": {},
   "source": [
    "### Is the mouse's hit rate different for familiar or novel change images? Is the change decoding accuracy curve different for familiar vs novel change images?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce64c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e511b6cf",
   "metadata": {},
   "source": [
    "### Are the accuracy curves different in active vs passive blocks?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f0b507",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a628ae2",
   "metadata": {},
   "source": [
    "### Are other variables, including behavioral variables, also encoded in the population activity? Can you decode the running speed, pupil diameter, or licking behavior?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78c801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d885d65d",
   "metadata": {},
   "source": [
    "### What about in a different brain area? For example, is the change encoded in CA1 activity? What about in the joint activity across brain areas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c273d78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swdb",
   "language": "python",
   "name": "swdb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
